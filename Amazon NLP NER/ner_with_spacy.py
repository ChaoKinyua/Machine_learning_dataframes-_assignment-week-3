# -*- coding: utf-8 -*-
"""NER with Spacy

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JlEU9f525zAsuls0vW88oosS0iir-Oo2

Amazon Product Review NLP Analysis with NER
"""

# Installation and setups
!pip install -q spacy spacytextblob textblob plotly pandas
!python -m spacy download en_core_web_sm
!python -m textblob.download_corpora

print("✅ Installation complete!")

# Importing dependencies
# ============================================================================
# CELL 2: IMPORT LIBRARIES
# ============================================================================

# Core NLP library
import spacy

# spaCy extension for sentiment analysis (TextBlob integration)
from spacytextblob.spacytextblob import SpacyTextBlob

# Data manipulation and analysis
import pandas as pd
import numpy as np

# Data visualization libraries
import matplotlib.pyplot as plt
import seaborn as sns

# Interactive visualizations
import plotly.express as px
import plotly.graph_objects as go

# For counting word frequencies or entity occurrences
from collections import Counter

# Suppress unnecessary warning messages
import warnings
warnings.filterwarnings('ignore')

df_full = pd.read_csv(
    "Reviews.csv",
    quotechar='"',
    doublequote=True,
    on_bad_lines='skip',
    engine='python',
    encoding='utf-8'
)

print(f"\n📊 Dataset Info:")
print(f"  • Total reviews: {len(df_full):,}")
print(f"  • Columns: {list(df_full.columns)}")
print(f"\nFirst few rows:")
print(df_full.head(2))

# Identify the correct column names
# Try to find review text column
text_col = None
for col in ['reviewText', 'review_text', 'text', 'review', 'Text']:
    if col in df_full.columns:
        text_col = col
        break

# find rating column
rating_col = None
for col in ['overall', 'rating', 'score', 'Rating', 'Overall', 'Score']:
    if col in df_full.columns:
        rating_col = col
        break

print(f"\n🎯 Using columns:")
print(f"  • Review text: {text_col}")
print(f"  • Rating: {rating_col}")

# Sample data for faster processing (adjust as needed)
SAMPLE_SIZE = 500  # Process 500 reviews for 2-hour sprint
df = df_full.sample(n=min(SAMPLE_SIZE, len(df_full)), random_state=42).copy()

# Standardize column names
df = df.rename(columns={
    text_col: 'reviewText',
    rating_col: 'rating'
})

print(df.columns.tolist())
df.head(2)

# Clean data
df = df.dropna(subset=['reviewText', 'rating'])
df['reviewText'] = df['reviewText'].astype(str)
df['rating'] = pd.to_numeric(df['rating'], errors='coerce')
df = df[df['reviewText'].str.len() > 20]  # Remove very short reviews

print(f"\n✅ Processed sample: {len(df)} reviews")
print(f"  • Average review length: {df['reviewText'].str.len().mean():.0f} characters")
print(f"  • Rating distribution:\n{df['rating'].value_counts().sort_index()}")
print(f"\n💡 Processing {len(df)} reviews (adjust SAMPLE_SIZE for more/less)")
print("\nSample reviews:")
print(df[['reviewText', 'rating']].head(3))

# INITIALIZE SPACY & NER

nlp = spacy.load('en_core_web_sm')
nlp.add_pipe('spacytextblob')

print("✅ spaCy model loaded with sentiment analysis!")

# EXTRACT ENTITIES & SENTIMENT
def extract_products_and_brands(text):
    """Extract product names and brand names from text"""
    doc = nlp(text)

    products = []
    brands = []

    for ent in doc.ents:
        if ent.label_ == 'PRODUCT':
            products.append(ent.text)
        elif ent.label_ == 'ORG':
            # Organizations are often brands
            brands.append(ent.text)

    return products, brands

def analyze_sentiment(text):
    """Analyze sentiment of text"""
    doc = nlp(text)
    polarity = doc._.blob.polarity  # -1 (negative) to 1 (positive)

    # Classify sentiment
    if polarity > 0.1:
        sentiment = 'Positive'
    elif polarity < -0.1:
        sentiment = 'Negative'
    else:
        sentiment = 'Neutral'

    return polarity, sentiment

# Process all reviews
print("Processing reviews...")
results = []

for idx, row in df.iterrows():
    text = row['reviewText']
    products, brands = extract_products_and_brands(text)
    polarity, sentiment = analyze_sentiment(text)

    results.append({
        'review': text[:100] + '...' if len(text) > 100 else text,
        'rating': row['rating'],
        'products': products,
        'brands': brands,
        'sentiment_score': round(polarity, 3),
        'sentiment': sentiment
    })

results_df = pd.DataFrame(results)
print(f"✅ Processed {len(results_df)} reviews")
print("\n" + "="*80)
print("SAMPLE RESULTS:")
print("="*80)
print(results_df.head(5).to_string())

# ENTITY ANALYSIS
# Extract all products and brands
all_products = []
all_brands = []

for products in results_df['products']:
    all_products.extend(products)

for brands in results_df['brands']:
    all_brands.extend(brands)

# Count occurrences
product_counts = Counter(all_products)
brand_counts = Counter(all_brands)

print("\n" + "="*80)
print("TOP EXTRACTED PRODUCTS:")
print("="*80)
for product, count in product_counts.most_common(10):
    print(f"  • {product}: {count} mentions")

print("\n" + "="*80)
print("TOP EXTRACTED BRANDS:")
print("="*80)
for brand, count in brand_counts.most_common(10):
    print(f"  • {brand}: {count} mentions")

#  SENTIMENT ANALYSIS SUMMARY
print("\n" + "="*80)
print("SENTIMENT ANALYSIS SUMMARY:")
print("="*80)

sentiment_dist = results_df['sentiment'].value_counts()
print(f"\n{sentiment_dist}\n")

avg_sentiment = results_df['sentiment_score'].mean()
print(f"Average Sentiment Score: {avg_sentiment:.3f}")
print(f"Sentiment Range: [{results_df['sentiment_score'].min():.3f}, {results_df['sentiment_score'].max():.3f}]")

# Correlation with ratings
correlation = results_df[['rating', 'sentiment_score']].corr().iloc[0, 1]
print(f"\nCorrelation between Rating and Sentiment: {correlation:.3f}")

# VISUALIZATIONS

# Visualization 1: Sentiment Distribution
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Pie chart
sentiment_dist.plot(kind='pie', ax=axes[0], autopct='%1.1f%%', startangle=90,
                    colors=['#2ecc71', '#e74c3c', '#95a5a6'])
axes[0].set_title('Sentiment Distribution', fontsize=14, fontweight='bold')
axes[0].set_ylabel('')

# Bar chart of sentiment scores
results_df['sentiment_score'].hist(bins=20, ax=axes[1], color='#3498db', edgecolor='black')
axes[1].set_title('Sentiment Score Distribution', fontsize=14, fontweight='bold')
axes[1].set_xlabel('Sentiment Score')
axes[1].set_ylabel('Frequency')
axes[1].axvline(0, color='red', linestyle='--', linewidth=2, label='Neutral')
axes[1].legend()

plt.tight_layout()
plt.show()

# Visualizing Top Brands
if brand_counts:
    top_brands = dict(brand_counts.most_common(8))

    fig = px.bar(x=list(top_brands.keys()), y=list(top_brands.values()),
                 title='Top Mentioned Brands',
                 labels={'x': 'Brand', 'y': 'Mentions'},
                 color=list(top_brands.values()),
                 color_continuous_scale='viridis')
    fig.update_layout(showlegend=False, height=400)
    fig.show()

# Visualization 3: Rating vs Sentiment
fig = px.scatter(results_df, x='rating', y='sentiment_score',
                 color='sentiment',
                 title='Rating vs Sentiment Score',
                 labels={'rating': 'Star Rating', 'sentiment_score': 'Sentiment Score'},
                 color_discrete_map={'Positive': '#2ecc71', 'Negative': '#e74c3c', 'Neutral': '#95a5a6'},
                 height=400)
fig.add_hline(y=0, line_dash="dash", line_color="red")
fig.show()

import plotly.graph_objects as go
from plotly.subplots import make_subplots

# -----------------------------
# Prepare Data
# -----------------------------
top_brands = dict(brand_counts.most_common(8)) if brand_counts else {}
top_products = dict(product_counts.most_common(8)) if product_counts else {}

# -----------------------------
# Create Subplots
# -----------------------------
fig = make_subplots(
    rows=3, cols=2,
    specs=[[{"type": "domain"}, {"type": "xy"}],
           [{"type": "xy"}, {"type": "xy"}],
           [{"colspan": 2, "type": "xy"}, None]],
    subplot_titles=(
        "Sentiment Distribution",
        "Sentiment Score Distribution",
        "Top Mentioned Brands",
        "Top Mentioned Products",
        "Rating vs Sentiment Score"
    )
)

# -----------------------------
# 1. Sentiment Pie Chart
# -----------------------------
fig.add_trace(
    go.Pie(
        labels=sentiment_dist.index,
        values=sentiment_dist.values,
        hole=0.3,
        marker_colors=['#2ecc71', '#95a5a6', '#e74c3c'],
        textinfo='label+percent'
    ),
    row=1, col=1
)

# -----------------------------
# 2. Sentiment Score Histogram
# -----------------------------
fig.add_trace(
    go.Histogram(
        x=results_df['sentiment_score'],
        nbinsx=20,
        marker_color='#3498db',
        name='Sentiment Score'
    ),
    row=1, col=2
)

# Add vertical line for neutral
fig.add_shape(
    go.layout.Shape(
        type="line", x0=0, x1=0,
        y0=0, y1=results_df['sentiment_score'].value_counts().max(),
        line=dict(color="red", dash="dash")
    ),
    row=1, col=2
)

# -----------------------------
# 3. Top Brands Bar Chart
# -----------------------------
if top_brands:
    fig.add_trace(
        go.Bar(
            x=list(top_brands.keys()),
            y=list(top_brands.values()),
            marker_color=list(top_brands.values()),
            name='Brands'
        ),
        row=2, col=1
    )

# -----------------------------
# 4. Top Products Bar Chart
# -----------------------------
if top_products:
    fig.add_trace(
        go.Bar(
            x=list(top_products.keys()),
            y=list(top_products.values()),
            marker_color=list(top_products.values()),
            name='Products'
        ),
        row=2, col=2
    )

# -----------------------------
# 5. Rating vs Sentiment Scatter
# -----------------------------
fig.add_trace(
    go.Scatter(
        x=results_df['rating'],
        y=results_df['sentiment_score'],
        mode='markers',
        marker=dict(
            color=results_df['sentiment'].map({'Positive':'#2ecc71','Neutral':'#95a5a6','Negative':'#e74c3c'}),
            size=8,
            line=dict(width=0.5, color='DarkSlateGrey')
        ),
        name='Rating vs Sentiment'
    ),
    row=3, col=1
)

# -----------------------------
# Layout & Styling
# -----------------------------
fig.update_layout(
    height=1200,
    showlegend=False,
    title_text="📊 Amazon Review Analysis Dashboard",
    title_x=0.5
)

fig.show()

# DETAILED ENTITY EXAMPLES
print("\n" + "="*80)
print("DETAILED EXAMPLES WITH ENTITIES:")
print("="*80)

for i in range(min(5, len(results_df))):
    row = results_df.iloc[i]
    print(f"\n📝 Review {i+1}:")
    print(f"Text: {row['review']}")
    print(f"Rating: {'⭐' * int(row['rating'])}")
    print(f"Extracted Products: {row['products'] if row['products'] else 'None detected'}")
    print(f"Extracted Brands: {row['brands'] if row['brands'] else 'None detected'}")
    print(f"Sentiment: {row['sentiment']} (Score: {row['sentiment_score']})")
    print("-" * 80)

# BRAND SENTIMENT ANALYSIS
# Create brand-sentiment mapping
brand_sentiments = {}

for idx, row in results_df.iterrows():
    for brand in row['brands']:
        if brand not in brand_sentiments:
            brand_sentiments[brand] = []
        brand_sentiments[brand].append(row['sentiment_score'])

# Calculate average sentiment per brand
brand_avg_sentiment = {brand: np.mean(scores)
                       for brand, scores in brand_sentiments.items()
                       if len(scores) > 0}

if brand_avg_sentiment:
    brand_sentiment_df = pd.DataFrame(
        list(brand_avg_sentiment.items()),
        columns=['Brand', 'Avg_Sentiment']
    ).sort_values('Avg_Sentiment', ascending=False)

    print("\n" + "="*80)
    print("BRAND SENTIMENT RANKINGS:")
    print("="*80)
    print(brand_sentiment_df.to_string(index=False))

# Visualization
if brand_avg_sentiment:
    fig = px.bar(brand_sentiment_df, x='Brand', y='Avg_Sentiment',
                 title='Average Sentiment by Brand',
                 color='Avg_Sentiment',
                 color_continuous_scale=['red', 'yellow', 'green'],
                 height=400)
    fig.add_hline(y=0, line_dash="dash", line_color="black")
    fig.show()

#Average Sentiment by Brand
if brand_avg_sentiment:
    fig = px.bar(
        brand_sentiment_df,
        x='Brand',
        y='Avg_Sentiment',
        title='Average Sentiment by Brand',
        color='Avg_Sentiment',
        color_continuous_scale=['red', 'yellow', 'green'],
        text=[f"{v:.2f}" for v in brand_sentiment_df['Avg_Sentiment']],
        height=400
    )
    fig.update_traces(textposition='outside')
    fig.add_hline(y=0, line_dash="dash", line_color="black")
    fig.show()

# Average Sentiment by Product
if product_avg_sentiment:
    top_product_sentiment = pd.DataFrame(
        list(product_avg_sentiment.items()), columns=['Product', 'Avg_Sentiment']
    ).sort_values('Avg_Sentiment', ascending=False).head(8)

    fig = px.bar(
        top_product_sentiment,
        x='Product',
        y='Avg_Sentiment',
        title='Average Sentiment by Product',
        color='Avg_Sentiment',
        color_continuous_scale=['red', 'yellow', 'green'],
        text=[f"{v:.2f}" for v in top_product_sentiment['Avg_Sentiment']],
        height=400
    )
    fig.update_traces(textposition='outside')
    fig.add_hline(y=0, line_dash="dash", line_color="black")
    fig.show()

# PRODUCT SENTIMENT ANALYSIS
# Create product-sentiment mapping
product_sentiments = {}

for idx, row in results_df.iterrows():
    for product in row['products']:
        if product not in product_sentiments:
            product_sentiments[product] = []
        product_sentiments[product].append(row['sentiment_score'])

# Calculate average sentiment per product
product_avg_sentiment = {product: np.mean(scores)
                         for product, scores in product_sentiments.items()
                         if len(scores) > 0}

if product_avg_sentiment:
    product_sentiment_df = pd.DataFrame(
        list(product_avg_sentiment.items()),
        columns=['Product', 'Avg_Sentiment']
    ).sort_values('Avg_Sentiment', ascending=False)

    print("\n" + "="*80)
    print("PRODUCT SENTIMENT RANKINGS:")
    print("="*80)
    print(product_sentiment_df.to_string(index=False))

# EXPORT RESULTS
# Save to CSV
results_df.to_csv('nlp_analysis_results.csv', index=False)

# Create summary report
summary = f"""
AMAZON PRODUCT REVIEW NLP ANALYSIS - SUMMARY REPORT
{'='*70}

DATASET STATISTICS:
  • Total Reviews Analyzed: {len(results_df)}
  • Total Products Detected: {len(all_products)}
  • Total Brands Detected: {len(all_brands)}
  • Unique Products: {len(product_counts)}
  • Unique Brands: {len(brand_counts)}

SENTIMENT ANALYSIS:
  • Positive Reviews: {sentiment_dist.get('Positive', 0)} ({sentiment_dist.get('Positive', 0)/len(results_df)*100:.1f}%)
  • Negative Reviews: {sentiment_dist.get('Negative', 0)} ({sentiment_dist.get('Negative', 0)/len(results_df)*100:.1f}%)
  • Neutral Reviews: {sentiment_dist.get('Neutral', 0)} ({sentiment_dist.get('Neutral', 0)/len(results_df)*100:.1f}%)
  • Average Sentiment Score: {avg_sentiment:.3f}
  • Sentiment-Rating Correlation: {correlation:.3f}

TOP 5 BRANDS:
{chr(10).join([f"  {i+1}. {brand} ({count} mentions)" for i, (brand, count) in enumerate(list(brand_counts.most_common(5)))])}

TOP 5 PRODUCTS:
{chr(10).join([f"  {i+1}. {product} ({count} mentions)" for i, (product, count) in enumerate(list(product_counts.most_common(5)))])}
"""

print(summary)

# Save summary
with open('analysis_summary.txt', 'w') as f:
    f.write(summary)

print("\n✅ Results exported!")
print("  • nlp_analysis_results.csv")
print("  • analysis_summary.txt")

from google.colab import files

print("\n📥 Downloading results...")
files.download('nlp_analysis_results.csv')
files.download('analysis_summary.txt')